# Default config for local text-to-video pipeline
# One prompt → one full video (single output file)

# Output
output:
  dir: "output"           # relative to project root
  filename_prefix: "video"
  # Format: 512, 720p (1280x720), 1080p (1920x1080)
  width: 512
  height: 512
  fps: 24
  # Quality tiers: draft (512), standard (720), high (1080)
  # Set quality: "draft" | "standard" | "high" to override width/height
  quality: null

# Video generation
video:
  # Max duration (seconds) per segment; longer videos are split into segments
  max_single_clip_seconds: 15
  # When duration > max_single_clip_seconds, we use temporal continuation and concat
  # No user-facing "scenes" — one full video file is always returned

# Learning (registry population)
# Short videos (e.g. 1s) are more efficient for the loop: fewer frames per run, one window per video,
# and more distinct prompts per hour → more diverse static/dynamic/narrative discoveries.
# See docs/WORKFLOW_EFFICIENCY_AND_REGISTRY_COMPLETION.md for completion targets and extraction tuning.
learning:
  # Duration (seconds) per video in the loop. 1s = learning-optimized (more prompts/hour, one window per video).
  duration_seconds: 1
  # Max frames to read per video for extraction (null = no limit). Caps CPU/decode for long clips.
  max_frames: 120
  # sample_every: 1 = every frame, 2 = every 2nd. Use 1 for short duration to maximize discovery per run.
  sample_every: 2

# Prompt (optional enrichment; can be disabled)
prompt:
  enrich: false            # set true when you add a local LLM
  # style_suffix: "cinematic, high quality"

# Paths (override via env or CLI)
# model_path: ""
# ffmpeg_bin: "ffmpeg"
